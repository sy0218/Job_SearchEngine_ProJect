# ğŸ“¦ consumer.service (Job Detail Scraper)
> êµ¬ì¸êµ¬ì§ ì‚¬ì´íŠ¸ ì±„ìš© ê³µê³ ì—ì„œ **ë°°ë„ˆ ì •ë³´ / ë³¸ë¬¸ í…ìŠ¤íŠ¸ / ì´ë¯¸ì§€**ë¥¼ ìˆ˜ì§‘í•˜ê³ 

> OCR ì²˜ë¦¬ìš© Kafka í† í”½ìœ¼ë¡œ **ì´ë¯¸ì§€ ë©”íƒ€ ë°ì´í„°**ë¥¼ ì „ì†¡í•˜ë©°

> **íŒŒì‹±í•œ ì±„ìš© ë°ì´í„°ì™€ ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬**ë¥¼ NFSì— ì €ì¥í•˜ëŠ” **ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤**ì…ë‹ˆë‹¤.

- **systemd ì„œë¹„ìŠ¤**ë¡œ ìë™ ì‹¤í–‰ ë° ê´€ë¦¬
- **Kafka â†’ Selenium â†’ Parser â†’ NFS íŒŒì´í”„ë¼ì¸**
- **Selenium + Scrapy** ê¸°ë°˜ ì±„ìš© ê³µê³  í¬ë¡¤ëŸ¬  
- Kafkaë¥¼ í†µí•´ **ì´ë¯¸ì§€ ë©”íƒ€ ë°ì´í„° ì „ì†¡**  
- NFSë¥¼ í†µí•´ **NDJSON ë°ì´í„° ë° ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ì €ì¥**  
- ë©€í‹°í”„ë¡œì„¸ìŠ¤ ë³‘ë ¬ ì²˜ë¦¬  
- í™˜ê²½ ì„¤ì • íŒŒì¼ë¡œ ë„ë©”ì¸/ì¡ë³„ ìˆ˜ì§‘ ê´€ë¦¬ 

---
<br>

## ğŸ”„ Consumer Pipline
![Pipline](https://github.com/user-attachments/assets/9d9312fd-1e75-42cb-81d8-8289983d18b2)

---
<br>

## ğŸ“‚ ì£¼ìš” íŒŒì¼ êµ¬ì¡°
| íŒŒì¼ëª… | ì„¤ëª… |
|--------|------|
| `consumer.service` | systemd ìœ ë‹› íŒŒì¼ (ì„œë¹„ìŠ¤ ê´€ë¦¬) |
| `consumer.sh` | í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ì„œë¹„ìŠ¤ ì‹œì‘/ì¤‘ì§€ ìŠ¤í¬ë¦½íŠ¸ |
| **`consumer.py` (ë©”ì¸)** | **ë©€í‹°í”„ë¡œì„¸ìŠ¤ ê¸°ë°˜ ì±„ìš© ê³µê³  ìˆ˜ì§‘ ë° ì „ì†¡** |
| `job.conf` | í™˜ê²½ ë³€ìˆ˜ ì„¤ì • íŒŒì¼ |
| `consumer.properties` | ë„ë©”ì¸/URL/XPath/ì´ë¯¸ì§€/NDJSON ì €ì¥ ê²½ë¡œ ì„¤ì • |
| `config_log.py` | ë¡œê·¸ ì„¤ì • (ë‚ ì§œë³„ íŒŒì¼ ìƒì„±) |
| `common/kafka_hook.py` | Kafka Producer/Consumer ë˜í¼ |
| `common/crawling_class.py` | Selenium ë˜í¼, ì±„ìš© ë°ì´í„° íŒŒì„œ |
| `common/job_class.py` | í™˜ê²½ ë³€ìˆ˜, StopChecker, ë°ì´í„° ì „ì²˜ë¦¬ ë° NFS ì €ì¥ í´ë˜ìŠ¤ |

---
<br>

## â–¶ï¸ ì„œë¹„ìŠ¤ ë™ì‘ íë¦„
```plaintext
systemd (consumer.service)
   â”‚
   â””â”€ consumer.py (_main)
          â”‚
          â”œâ”€ í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • ë¡œë“œ
          â”œâ”€ Kafka Consumer + Producer ì—°ê²°
          â”œâ”€ ChromeDriver ë¸Œë¼ìš°ì € ì‹œì‘
          â”‚
          â”œâ”€ ë©€í‹°í”„ë¡œì„¸ìŠ¤ ì›Œì»¤ ì´ˆê¸°í™” (ProcessPoolExecutor)
          â”‚
          â”œâ”€ Kafka ë°°ì¹˜ ë©”ì‹œì§€ ìˆ˜ì‹ 
          â”‚    â”œâ”€ Job URL ì ‘ì†
          â”‚    â”œâ”€ í˜ì´ì§€ ëŒ€ê¸° & ìë™ ìŠ¤í¬ë¡¤
          â”‚    â”œâ”€ HTML â†’ Scrapy TextResponse ë³€í™˜
          â”‚    â”œâ”€ ì±„ìš© ë°ì´í„° ì¶”ì¶œ (ë°°ë„ˆ, ë³¸ë¬¸ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€)
          â”‚    â”œâ”€ ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ â†’ NFS ì €ì¥
          â”‚    â”œâ”€ NDJSON ë°ì´í„° â†’ NFS ì €ì¥
          â”‚    â””â”€ ì´ë¯¸ì§€ ë©”íƒ€ ì •ë³´ â†’ Kafka OCR í† í”½ ì „ì†¡
          â”‚
          â””â”€ Stop íŒŒì¼ ê°ì§€ ì‹œ ì•ˆì „ ì¢…ë£Œ
```

---
<br>

## ğŸŒŸ ì£¼ìš” íŠ¹ì§•
- ì±„ìš© ê³µê³  ë°°ë„ˆ/ë³¸ë¬¸/ì´ë¯¸ì§€ ì¶”ì¶œ
- ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì •ë¦¬ (íŠ¹ìˆ˜ë¬¸ì ì œê±°, ê³µë°± ì •ë¦¬)
- ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ NFS ì €ì¥
- íŒŒì‹± ë°ì´í„° NDJSON NFS ì €ì¥
- OCR Kafka í† í”½ìœ¼ë¡œ ì´ë¯¸ì§€ í•´ì‹œ ì „
- ë©€í‹°í”„ë¡œì„¸ìŠ¤ë¡œ íš¨ìœ¨ì  ìˆ˜ì§‘
- Stop í”Œë˜ê·¸ ê°ì§€ ì‹œ ì•ˆì „ ì¢…ë£Œ
- ë°ì´í„° ì˜ˆì‹œ
```json
{
  "domain": "remember",
  "href": "...",
  "company": "...",
  "title": "...",
  "msgid": "...",
  "body_text": "...",
  "body_img": ["0d8dd5659bfb18d2fe4d496a9531b652..."],
  "pay": "...",
  "location": "...",
  "career": "...",
  "education": "...",
  "deadline": "...",
  "type": "..."
}
```

---
<br>

## ğŸ“‹ í™˜ê²½ ë³€ìˆ˜ (job.conf)
```bash
export PYTHONPATH=/work/job_project
export JOB_LIB=/work/jsy/job_project/lib

# ì»¬ë ‰í„° (service)
export COLLECTOR_CONFIG_PATH=/work/job_project/collector/conf/collector.properties
export COLLECTOR_WORK_DIR=/work/job_project/collector
export COLLECTOR_STOP_DIR=/work/job_project/collector/control
export COLLECTOR_STOP_FILE=collector.stop
export COLLECTOR_LOG_FILE=/work/job_project/logs/collector/collector

# ì»¨ìŠˆë¨¸ (service)
export CONSUMER_CONFIG_PATH=/work/job_project/consumer/conf/consumer.properties
export CONSUMER_WORK_DIR=/work/job_project/consumer
export CONSUMER_STOP_DIR=/work/job_project/consumer/control
export CONSUMER_STOP_FILE=consumer.stop
export CONSUMER_LOG_FILE=/work/job_project/logs/consumer/consumer

# í•˜ë‘¡ ì—…ë¡œë“œ (service)
export HD_UPLOAD_CONFIG_PATH=/work/jsy/job_project/hadoop_upload/conf/hadoop_upload.properties
export HD_UPLOAD_WORK_DIR=/work/jsy/job_project/hadoop_upload
export HD_UPLOAD_STOP_DIR=/work/jsy/job_project/hadoop_upload/control
export HD_UPLOAD_STOP_FILE=hadoop_upload.stop
export HD_UPLOAD_LOG_DIR=/work/jsy/job_project/logs/hadoop_upload

# í•˜ë‘¡ ì´ë²¤íŠ¸ (service)
export HD_EVENT_CONFIG_PATH=/work/jsy/job_project/hadoop_event/conf/hadoop_event.properties
export HD_EVENT_WORK_DIR=/work/jsy/job_project/hadoop_event
export HD_EVENT_LOG_DIR=/work/jsy/job_project/logs/hadoop_event

# ocr (service)
export OCR_CONFIG_PATH=/work/job_project/ocr/conf/ocr.properties
export OCR_WORK_DIR=/work/job_project/ocr
export OCR_STOP_DIR=/work/job_project/ocr/control
export OCR_STOP_FILE=ocr.stop
export OCR_LOG_FILE=/work/job_project/logs/ocr/ocr

# ì›¨ì–´í•˜ìš°ìŠ¤ (service)
export WAREHOUSE_CONFIG_PATH=/work/job_project/warehouse/conf/warehouse.properties
export WAREHOUSE_WORK_DIR=/work/job_project/warehouse
export WAREHOUSE_STOP_DIR=/work/job_project/warehouse/control
export WAREHOUSE_STOP_FILE=warehouse.stop
export WAREHOUSE_LOG_FILE=/work/job_project/logs/warehouse/warehouse

# ì—˜ë¼ìŠ¤í‹±ì„œì¹˜ ì—…ë¡œë“œ (service)
export ES_UPLOAD_CONFIG_PATH=/work/job_project/es_upload/conf/es_upload.properties
export ES_UPLOAD_WORK_DIR=/work/job_project/es_upload
export ES_UPLOAD_STOP_DIR=/work/job_project/es_upload/control
export ES_UPLOAD_STOP_FILE=es_upload.stop
export ES_UPLOAD_LOG_FILE=/work/job_project/logs/es_upload/es_upload

# redis (app)
export REDIS_HOST=192.168.122.59
export REDIS_PORT=6379
export REDIS_DB_JOB=0
export REDIS_DB_IMG=1
export REDIS_PASSWORD=1234
export REDIS_JOBHEAD_KEY=job_set

# kafka (app)
export KAFKA_HOST=192.168.122.60:9092,192.168.122.61:9092,192.56.122.62:9092
export SCHEMA_REGISTRY=http://192.168.122.59:8081
export JOB_TOPIC=job_header_topic
export JOB_GROUP_ID=job-group
export OCR_TOPIC=ocr_img
export OCR_GROUP_ID=ocr-group

# postgresql (app)
export POSTGRESQL_HOST=192.168.122.59
export POSTGRESQL_PORT=5432
export POSTGRESQL_DB=job_pro
export POSTGRESQL_USER=sjj
export POSTGRESQL_PASSWORD=1234

# hadoop (app)
export HADOOP_FS_NAME=job-cluster
export HADOOP_USER=root

# elasticsearch (app)
export ES_HOST=http://192.168.122.63:9200,http://192.168.122.64:9200,http://192.168.122.65:9200
export ES_JOB_INDEX=job_postings_v1

# nfs
export NFS_DATA=/nfs/job_data
export NFS_IMG=/nfs/img
```

---
<br>

## ğŸ“‹ ì„¤ì • íŒŒì¼ (consumer.properties)
```ini
# =========================
# Kafka Consumer Partition ì„¤ì •
# =========================
[partition_num]
num=1

# =========================
# Kafka Poll ì˜µì…˜
# ========================
[poll_opt]
poll_size=5

# =========================
# ì´ë¯¸ì§€ í•„í„°ë§ ì˜µì…˜
# =========================
[img_bypass]
# ìµœì†Œ ì´ë¯¸ì§€ ë„ˆë¹„
width=50
# ìµœì†Œ ì´ë¯¸ì§€ ë†’ì´
height=50
# ìµœì†Œ ì´ë¯¸ì§€ ìš©ëŸ‰( KB )
size=20

# =========================
# í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ XPath
# =========================
[xpath]
remember.body=//div[@class='sc-70f5b6f6-0 kXwJGP']
remember.banner=//span[contains(normalize-space(), '{kw}')]/following-sibling::*[1]//text()
remember.wait=div[class='sc-884c2c6c-2 jwCPBj']

jobplanet.body=//div[@class='recruitment-detail__box']
jobplanet.banner=//div[contains(@class, 'recruitment-summary')]//dt[contains(., '{kw}')]/following-sibling::dd[1]//text()
jobplanet.wait=div[class='job_body']

wanted.body=//div[@class='JobDescription_JobDescription__paragraph__wrapper__WPrKC']
wanted.banner=//span[contains(@class, 'JobHeader_JobHeader__Tools__Company__Info') and contains(text(), '{kw}')]/text()|//h2[contains(text(), '{kw}')]/following-sibling::span[contains(@class, 'wds')]/text()|//h2[contains(text(), '{kw}')]/following-sibling::*//span[contains(@class, 'wds')]/text()
wanted.wait=section[class='JobContent_JobContent__Qb6DR']

saramin.body=//div[@class='cont']
saramin.banner=//div[contains(@class,'cont')]//dt[normalize-space()='{kw}']/following-sibling::dd[1]/strong/text()|//div[contains(@class,'cont')]//dt[normalize-space()='{kw}']/following-sibling::dd[1]//text()|//div[contains(@class,'status')]//dt[normalize-space()='{kw}']/following-sibling::dd[1]/text()
saramin.wait=div[class='wrap_jv_cont']


# =========================
# ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ë§ ì˜µì…˜ & í˜ì´ì§€ ì—†ìŒ í…ìŠ¤íŠ¸
# =========================
[option]
saramin.setup_flag=n
remember.setup_flag=n
jobplanet.setup_flag=n
wanted.setup_flag=y
no_page_text=í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”|í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤|ì±„ìš©ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤


# =========================
# ìë™ í•„í„° ì„¤ì • XPath ( ì§êµ° ì„ íƒ â†’ ì ìš© ë²„íŠ¼ê¹Œì§€ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ )
# option í•­ëª©ì˜ setup_flag = y ì¸ ì‚¬ì´íŠ¸ì—ì„œë§Œ ì‚¬ìš©
# =========================
[auto_setup]
wanted=//button[.//span[contains(text(), 'ìƒì„¸ ì •ë³´ ë” ë³´ê¸°')]]


# =========================
# Kafka ì§ë ¬í™” ìŠ¤í‚¤ë§ˆ íŒŒì¼ ê²½ë¡œ
# =========================
[schema]
job_header=/work/job_project/schema/kafka/job_header.avsc
```

---
<br>

## â–¶ï¸ ì„œë¹„ìŠ¤ ì‹¤í–‰
```bash
# ì‹œì‘
sudo systemctl start consumer.service

# ì¤‘ì§€
sudo systemctl stop consumer.service

# ìƒíƒœ í™•ì¸
sudo systemctl status consumer.service
```

---
<br>

## ğŸ“œ ë¡œê·¸
- ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜: `$CONSUMER_LOG_FILE_YYYYMMDD.log`
- ì˜ˆì‹œ: `/work/job_project/logs/consumer_20260128.log`
- INFO ë ˆë²¨ ì´ìƒì˜ ë¡œê·¸ ê¸°ë¡

---
<br>

## âœ… ì£¼ì˜ ì‚¬í•­
1) Stop íŒŒì¼ (`consumer.stop`) ìƒì„± ì‹œ Consumerê°€ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë¨  
2) ChromeDriverëŠ” Headless ëª¨ë“œ + ëœë¤ User-Agent ì ìš©  
3) **Kafka Avro ì „ì†¡ ì‹œ Schema ë“±ë¡ í•„ìš”**  
4) **NDJSON ë°ì´í„°ì™€ ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ëª¨ë‘ NFSì— ì €ì¥ ( NFS ë§ˆìš´íŠ¸ í•„ìˆ˜ )**
5) ì´ë¯¸ì§€ Kafka ì „ì†¡ì€ **í•´ì‹œê°’ë§Œ**  
---
