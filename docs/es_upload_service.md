# ğŸ“¤ es_upload.service (Elasticsearch Upload Service)

> HDFSì— ì €ì¥ëœ **Elasticsearch Bulk NDJSON gzip íŒŒì¼ì„ ì½ì–´** â†’ **Elasticsearchë¡œ ì—…ë¡œë“œ**í•˜ê³   

> ì²˜ë¦¬ ì™„ë£Œ ìƒíƒœë¥¼ **PostgreSQLì— ê¸°ë¡**í•˜ëŠ” **ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤**ì…ë‹ˆë‹¤.

- **systemd ì„œë¹„ìŠ¤** ê¸°ë°˜ ìë™ ì‹¤í–‰
- HDFS gzip NDJSON ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
- Elasticsearch Bulk ì—…ë¡œë“œ
- PostgreSQL ì²˜ë¦¬ ìƒíƒœ ê´€ë¦¬
- Chunk ë‹¨ìœ„ ì—…ë¡œë“œ ìµœì í™”
- Stop íŒŒì¼ ê¸°ë°˜ ì•ˆì „ ì¢…ë£Œ

---
<br>

## ğŸ“‚ ì£¼ìš” íŒŒì¼ êµ¬ì¡°

| íŒŒì¼ëª… | ì„¤ëª… |
|------|------|
| `es_upload.service` | systemd ìœ ë‹› íŒŒì¼ (ì„œë¹„ìŠ¤ ê´€ë¦¬) |
| `es_upload.sh` | í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ì„œë¹„ìŠ¤ ì‹œì‘/ì¤‘ì§€ ìŠ¤í¬ë¦½íŠ¸ |
| **`es_upload.py` (ë©”ì¸)** | **HDFS â†’ Elasticsearch Bulk ì—…ë¡œë“œ â†’ DB ì»¤ë°‹** |
| `job.conf` | í™˜ê²½ ë³€ìˆ˜ ì„¤ì • íŒŒì¼ |
| `es_upload.properties` | SQL ì¿¼ë¦¬ ë° ì—…ë¡œë“œ ì„¤ì • |
| `config_log.py` | ë¡œê·¸ ì„¤ì • (ë‚ ì§œë³„ íŒŒì¼ ìƒì„±) |
| `common/postgres_hook.py` | PostgreSQL Hook |
| `common/hdfs_hook.py` | HDFS Hook |
| `common/es_hook.py` | Elasticsearch Hook |
| `common/job_class.py` | í™˜ê²½ ë³€ìˆ˜ ë° StopChecker |

---
<br>

## â–¶ï¸ ì„œë¹„ìŠ¤ ë™ì‘ íë¦„

```plaintext
systemd (es_upload.service)
   â”‚
   â””â”€ docker exec es_upload
          â”‚
          â””â”€ es_upload.sh start
                 â”‚
                 â””â”€ es_upload.py (_main)
                        â”‚
                        â”œâ”€ í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • ë¡œë“œ
                        â”œâ”€ PostgreSQL / HDFS / Elasticsearch ì—°ê²°
                        â”‚
                        â””â”€ ë©”ì¸ ë£¨í”„ ì‹œì‘
                             â”œâ”€ Stop íŒŒì¼ ê°ì§€
                             â”‚    â””â”€ ê°ì§€ ì‹œ ì•ˆì „ ì¢…ë£Œ
                             â”‚
                             â”œâ”€ ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼ ì¡°íšŒ (PostgreSQL)
                             â”‚    â””â”€ ëŒ€ìƒ ì—†ìœ¼ë©´ ëŒ€ê¸° í›„ ì¬ì‹œë„
                             â”‚
                             â”œâ”€ HDFS gzip NDJSON íŒŒì¼ ì½ê¸°
                             â”œâ”€ Bulk Generator ìƒì„±
                             â”‚
                             â”œâ”€ Elasticsearch Chunk ì—…ë¡œë“œ
                             â”œâ”€ ì²˜ë¦¬ ì™„ë£Œ DB ì»¤ë°‹
                             â”‚
                             â””â”€ ë‹¤ìŒ ë°°ì¹˜ ì²˜ë¦¬
```

---
<br>

## ğŸŒŸ ì£¼ìš” íŠ¹ì§•
- HDFS gzip NDJSON ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
- Elasticsearch Bulk Chunk ì—…ë¡œë“œ
- ë©”ëª¨ë¦¬ ì ˆì•½í˜• Generator ë°©ì‹ ì²˜ë¦¬
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
- PostgreSQL ê¸°ë°˜ ì²˜ë¦¬ ìƒíƒœ ê´€ë¦¬
- Stop íŒŒì¼ ê¸°ë°˜ ì•ˆì „ ì¢…ë£Œ
---
### ğŸ“¦ Elasticsearch Bulk í¬ë§· ì˜ˆì‹œ
```json
{ "index": { "_index": "job_postings_v1", "_id": "msgid" } }
{
  "domain": "...",
  "company": "...",
  "title": "...",
  "body_text": "...",
  "morph": ["python", "ë°ì´í„°", "ì—”ì§€ë‹ˆì–´"]
}
```

---
<br>

## ğŸ“‹ í™˜ê²½ ë³€ìˆ˜ (job.conf)
```bash
export PYTHONPATH=/work/job_project
export JOB_LIB=/work/jsy/job_project/lib

# ì»¬ë ‰í„° (service)
export COLLECTOR_CONFIG_PATH=/work/job_project/collector/conf/collector.properties
export COLLECTOR_WORK_DIR=/work/job_project/collector
export COLLECTOR_STOP_DIR=/work/job_project/collector/control
export COLLECTOR_STOP_FILE=collector.stop
export COLLECTOR_LOG_FILE=/work/job_project/logs/collector/collector

# ì»¨ìŠˆë¨¸ (service)
export CONSUMER_CONFIG_PATH=/work/job_project/consumer/conf/consumer.properties
export CONSUMER_WORK_DIR=/work/job_project/consumer
export CONSUMER_STOP_DIR=/work/job_project/consumer/control
export CONSUMER_STOP_FILE=consumer.stop
export CONSUMER_LOG_FILE=/work/job_project/logs/consumer/consumer

# í•˜ë‘¡ ì—…ë¡œë“œ (service)
export HD_UPLOAD_CONFIG_PATH=/work/jsy/job_project/hadoop_upload/conf/hadoop_upload.properties
export HD_UPLOAD_WORK_DIR=/work/jsy/job_project/hadoop_upload
export HD_UPLOAD_STOP_DIR=/work/jsy/job_project/hadoop_upload/control
export HD_UPLOAD_STOP_FILE=hadoop_upload.stop
export HD_UPLOAD_LOG_DIR=/work/jsy/job_project/logs/hadoop_upload

# í•˜ë‘¡ ì´ë²¤íŠ¸ (service)
export HD_EVENT_CONFIG_PATH=/work/jsy/job_project/hadoop_event/conf/hadoop_event.properties
export HD_EVENT_WORK_DIR=/work/jsy/job_project/hadoop_event
export HD_EVENT_LOG_DIR=/work/jsy/job_project/logs/hadoop_event

# ocr (service)
export OCR_CONFIG_PATH=/work/job_project/ocr/conf/ocr.properties
export OCR_WORK_DIR=/work/job_project/ocr
export OCR_STOP_DIR=/work/job_project/ocr/control
export OCR_STOP_FILE=ocr.stop
export OCR_LOG_FILE=/work/job_project/logs/ocr/ocr

# ì›¨ì–´í•˜ìš°ìŠ¤ (service)
export WAREHOUSE_CONFIG_PATH=/work/job_project/warehouse/conf/warehouse.properties
export WAREHOUSE_WORK_DIR=/work/job_project/warehouse
export WAREHOUSE_STOP_DIR=/work/job_project/warehouse/control
export WAREHOUSE_STOP_FILE=warehouse.stop
export WAREHOUSE_LOG_FILE=/work/job_project/logs/warehouse/warehouse

# ì—˜ë¼ìŠ¤í‹±ì„œì¹˜ ì—…ë¡œë“œ (service)
export ES_UPLOAD_CONFIG_PATH=/work/job_project/es_upload/conf/es_upload.properties
export ES_UPLOAD_WORK_DIR=/work/job_project/es_upload
export ES_UPLOAD_STOP_DIR=/work/job_project/es_upload/control
export ES_UPLOAD_STOP_FILE=es_upload.stop
export ES_UPLOAD_LOG_FILE=/work/job_project/logs/es_upload/es_upload

# redis (app)
export REDIS_HOST=192.168.122.59
export REDIS_PORT=6379
export REDIS_DB_JOB=0
export REDIS_DB_IMG=1
export REDIS_PASSWORD=1234
export REDIS_JOBHEAD_KEY=job_set

# kafka (app)
export KAFKA_HOST=192.168.122.60:9092,192.168.122.61:9092,192.56.122.62:9092
export SCHEMA_REGISTRY=http://192.168.122.59:8081
export JOB_TOPIC=job_header_topic
export JOB_GROUP_ID=job-group
export OCR_TOPIC=ocr_img
export OCR_GROUP_ID=ocr-group

# postgresql (app)
export POSTGRESQL_HOST=192.168.122.59
export POSTGRESQL_PORT=5432
export POSTGRESQL_DB=job_pro
export POSTGRESQL_USER=sjj
export POSTGRESQL_PASSWORD=1234

# hadoop (app)
export HADOOP_FS_NAME=job-cluster
export HADOOP_USER=root

# elasticsearch (app)
export ES_HOST=http://192.168.122.63:9200,http://192.168.122.64:9200,http://192.168.122.65:9200
export ES_JOB_INDEX=job_postings_v1

# nfs
export NFS_DATA=/nfs/job_data
export NFS_IMG=/nfs/img
```

---
<br>

## ğŸ“‹ ì„¤ì • íŒŒì¼ (es_upload.properties)
```ini
[sql]
select_hadoop_new=SELECT file_path FROM job.hadoop_new WHERE event_check IS NULL ORDER BY id LIMIT 1;
update_hadoop_event=UPDATE job.hadoop_event SET event_check = TRUE WHERE event_check IS NULL and file_path = %s

[es]
chunk=100
timeout=120
```

---
<br>

## â–¶ï¸ ì„œë¹„ìŠ¤ ì‹¤í–‰
```bash
# ì‹œì‘
sudo systemctl start es_upload.service

# ì¤‘ì§€
sudo systemctl stop es_upload.service

# ìƒíƒœ í™•ì¸
sudo systemctl status es_upload.service
```

---
<br>

## ğŸ“œ ë¡œê·¸
- ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜: `$ES_UPLOAD_LOG_FILE_YYYYMMDD.log`
- ì˜ˆì‹œ: `/work/job_project/logs/es_upload/es_upload_20260128.log`

---
<br>

## âœ… ì£¼ì˜ ì‚¬í•­
1) Stop íŒŒì¼ (`es_upload.stop`) ìƒì„± ì‹œ ì•ˆì „ ì¢…ë£Œë¨
2) HDFS íŒŒì¼ì€ ë°˜ë“œì‹œ **gzip NDJSON Bulk í¬ë§·**ì´ì–´ì•¼ í•¨
3) Elasticsearch ì—…ë¡œë“œëŠ” **Chunk ë‹¨ìœ„ë¡œ** ì²˜ë¦¬ë¨
4) **ì—…ë¡œë“œ ì™„ë£Œ í›„ PostgreSQL ìƒíƒœê°€ ì»¤ë°‹ë¨**
5) ì²˜ë¦¬ ëŒ€ìƒì´ ì—†ìœ¼ë©´ ìë™ ëŒ€ê¸° í›„ ì¬ì‹œë„
---
