# ğŸ›¢ï¸ warehouse.service (Job Data Warehouse)
> ìˆ˜ì§‘Â·ê°€ê³µëœ **ì±„ìš© ê³µê³  ë°ì´í„°ì™€ OCR ê²°ê³¼ë¥¼ ë³‘í•©**í•˜ì—¬ â†’ **í˜•íƒœì†Œ ë¶„ì„ì„ ìˆ˜í–‰**í•˜ê³ 

> Elasticsearch Bulk ì—…ë¡œë“œìš© ë°ì´í„°ë¥¼ **HDFSì— ì ì¬**í•˜ëŠ” **ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤**ì…ë‹ˆë‹¤.

- **systemd ì„œë¹„ìŠ¤**ë¡œ ìë™ ì‹¤í–‰ ë° ê´€ë¦¬  
- Redis OCR ê²°ê³¼ ëŒ€ê¸° ë° ë³‘í•© ì²˜ë¦¬  
- PostgreSQL ê¸°ë°˜ ì²˜ë¦¬ ìƒíƒœ ê´€ë¦¬  
- Hadoop(HDFS) ì—°ë™ ë°ì´í„° ì²˜ë¦¬  
- Kiwi + spaCy ê¸°ë°˜ í˜•íƒœì†Œ ë¶„ì„  
- Stop íŒŒì¼ ê¸°ë°˜ ì•ˆì „ ì¢…ë£Œ  

---
<br>

## ğŸ“‚ ì£¼ìš” íŒŒì¼ êµ¬ì¡°
| íŒŒì¼ëª… | ì„¤ëª… |
|------|------|
| `warehouse.service` | systemd ìœ ë‹› íŒŒì¼ (ì„œë¹„ìŠ¤ ê´€ë¦¬) |
| `warehouse.sh` | í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ì„œë¹„ìŠ¤ ì‹œì‘/ì¤‘ì§€ ìŠ¤í¬ë¦½íŠ¸ |
| **`warehouse.py` (ë©”ì¸)** | **HDFS â†’ Redis â†’ í˜•íƒœì†Œ ë¶„ì„ â†’ HDFS ì ì¬** |
| `job.conf` | í™˜ê²½ ë³€ìˆ˜ ì„¤ì • íŒŒì¼ |
| `warehouse.properties` | SQL ì¿¼ë¦¬ ë° HDFS ê²½ë¡œ ì„¤ì • |
| `config_log.py` | ë¡œê·¸ ì„¤ì • (ë‚ ì§œë³„ íŒŒì¼ ìƒì„±) |
| `common/hook_class.py` | Redis / PostgreSQL / HDFS Hook |
| `common/job_class.py` | í™˜ê²½ ë³€ìˆ˜, StopChecker, ë°ì´í„° ì „ì²˜ë¦¬ ìœ í‹¸ |
| `common/morph_analyzer.py` | í˜•íƒœì†Œ ë¶„ì„ (Kiwi + spaCy) |

---
<br>

## â–¶ï¸ ì„œë¹„ìŠ¤ ë™ì‘ íë¦„
```plaintext
systemd (warehouse.service)
   â”‚
   â””â”€ docker exec warehouse
          â”‚
          â””â”€ warehouse.sh start
                 â”‚
                 â””â”€ warehouse.py (_main)
                        â”‚
                        â”œâ”€ í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • ë¡œë“œ
                        â”œâ”€ Redis / PostgreSQL / HDFS ì—°ê²°
                        â”œâ”€ í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
                        â”‚
                        â””â”€ ë©”ì¸ ë£¨í”„ ì‹œì‘
                             â”œâ”€ Stop íŒŒì¼ ê°ì§€
                             â”‚    â””â”€ ê°ì§€ ì‹œ ì•ˆì „ ì¢…ë£Œ
                             â”‚
                             â”œâ”€ ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼ ì¡°íšŒ (PostgreSQL)
                             â”‚    â””â”€ ëŒ€ìƒ ì—†ì„ ê²½ìš° ëŒ€ê¸° í›„ ì¬ì‹œë„
                             â”‚
                             â”œâ”€ HDFS gzip NDJSON íŒŒì¼ ì½ê¸°
                             â”œâ”€ Redis OCR ê²°ê³¼ ëŒ€ê¸° ë° ë³‘í•©
                             â”‚
                             â”œâ”€ ë³¸ë¬¸ + OCR í…ìŠ¤íŠ¸ í˜•íƒœì†Œ ë¶„ì„
                             â”œâ”€ Elasticsearch Bulk í¬ë§· ìƒì„±
                             â”‚
                             â”œâ”€ Bulk ë°ì´í„° HDFS gzip ì—…ë¡œë“œ
                             â”œâ”€ ì²˜ë¦¬ ì™„ë£Œ ìƒíƒœ DB ì»¤ë°‹
                             â”‚
                             â””â”€ ë‹¤ìŒ ë°°ì¹˜ ì²˜ë¦¬
```

---
<br>

## ğŸŒŸ ì£¼ìš” íŠ¹ì§•
- HDFS gzip NDJSON íŒŒì¼ ì²˜ë¦¬
- Redis ê¸°ë°˜ OCR ê²°ê³¼ ëŒ€ê¸° ë° ë³‘í•©
- ë³¸ë¬¸ + ì´ë¯¸ì§€ OCR í…ìŠ¤íŠ¸ í†µí•© ì²˜ë¦¬
- í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ê²€ìƒ‰ í† í° ìƒì„±
- Elasticsearch Bulk ì—…ë¡œë“œ í¬ë§· ìƒì„±
- ê²°ê³¼ ë°ì´í„° HDFS gzip ì ì¬
- Stop íŒŒì¼ ê¸°ë°˜ ì•ˆì „ ì¢…ë£Œ
- **ë°ì´í„° ì˜ˆì‹œ (ES Bulk) â¤µ**
```json
{ "index": { "_index": "job_postings_v1", "_id": "msgid" } }
{
  "domain": "...",
  "company": "...",
  "title": "...",
  "body_text": "...",
  "morph": ["python", "ë°ì´í„°", "ì—”ì§€ë‹ˆì–´"],
  "pay": "...",
  "location": "...",
  "career": "...",
  "education": "...",
  "deadline": "...",
  "type": "..."
}
```

---
<br>

## ğŸ“‹ í™˜ê²½ ë³€ìˆ˜ (job.conf)
```bash
export PYTHONPATH=/work/job_project
export JOB_LIB=/work/jsy/job_project/lib

# ì»¬ë ‰í„° (service)
export COLLECTOR_CONFIG_PATH=/work/job_project/collector/conf/collector.properties
export COLLECTOR_WORK_DIR=/work/job_project/collector
export COLLECTOR_STOP_DIR=/work/job_project/collector/control
export COLLECTOR_STOP_FILE=collector.stop
export COLLECTOR_LOG_FILE=/work/job_project/logs/collector/collector

# ì»¨ìŠˆë¨¸ (service)
export CONSUMER_CONFIG_PATH=/work/job_project/consumer/conf/consumer.properties
export CONSUMER_WORK_DIR=/work/job_project/consumer
export CONSUMER_STOP_DIR=/work/job_project/consumer/control
export CONSUMER_STOP_FILE=consumer.stop
export CONSUMER_LOG_FILE=/work/job_project/logs/consumer/consumer

# í•˜ë‘¡ ì—…ë¡œë“œ (service)
export HD_UPLOAD_CONFIG_PATH=/work/jsy/job_project/hadoop_upload/conf/hadoop_upload.properties
export HD_UPLOAD_WORK_DIR=/work/jsy/job_project/hadoop_upload
export HD_UPLOAD_STOP_DIR=/work/jsy/job_project/hadoop_upload/control
export HD_UPLOAD_STOP_FILE=hadoop_upload.stop
export HD_UPLOAD_LOG_DIR=/work/jsy/job_project/logs/hadoop_upload

# í•˜ë‘¡ ì´ë²¤íŠ¸ (service)
export HD_EVENT_CONFIG_PATH=/work/jsy/job_project/hadoop_event/conf/hadoop_event.properties
export HD_EVENT_WORK_DIR=/work/jsy/job_project/hadoop_event
export HD_EVENT_LOG_DIR=/work/jsy/job_project/logs/hadoop_event

# ocr (service)
export OCR_CONFIG_PATH=/work/job_project/ocr/conf/ocr.properties
export OCR_WORK_DIR=/work/job_project/ocr
export OCR_STOP_DIR=/work/job_project/ocr/control
export OCR_STOP_FILE=ocr.stop
export OCR_LOG_FILE=/work/job_project/logs/ocr/ocr

# ì›¨ì–´í•˜ìš°ìŠ¤ (service)
export WAREHOUSE_CONFIG_PATH=/work/job_project/warehouse/conf/warehouse.properties
export WAREHOUSE_WORK_DIR=/work/job_project/warehouse
export WAREHOUSE_STOP_DIR=/work/job_project/warehouse/control
export WAREHOUSE_STOP_FILE=warehouse.stop
export WAREHOUSE_LOG_FILE=/work/job_project/logs/warehouse/warehouse

# redis (app)
export REDIS_HOST=192.168.122.59
export REDIS_PORT=6379
export REDIS_DB_JOB=0
export REDIS_DB_IMG=1
export REDIS_PASSWORD=1234
export REDIS_JOBHEAD_KEY=job_set

# kafka (app)
export KAFKA_HOST=192.168.122.60:9092,192.168.122.61:9092,192.56.122.62:9092
export SCHEMA_REGISTRY=http://192.168.122.59:8081
export JOB_TOPIC=job_header_topic
export JOB_GROUP_ID=job-group
export OCR_TOPIC=ocr_img
export OCR_GROUP_ID=ocr-group

# postgresql (app)
export POSTGRESQL_HOST=192.168.122.59
export POSTGRESQL_PORT=5432
export POSTGRESQL_DB=job_pro
export POSTGRESQL_USER=sjj
export POSTGRESQL_PASSWORD=1234

# hadoop (app)
export HADOOP_FS_NAME=job-cluster
export HADOOP_USER=root

# elasticsearch (app)
export ES_JOB_INDEX=job_postings_v1

# nfs
export NFS_DATA=/nfs/job_data
export NFS_IMG=/nfs/img
```

---
<br>

## ğŸ“‹ ì„¤ì • íŒŒì¼ (warehouse.properties)
```ini
[sql]
select_hadoop_org=SELECT file_path FROM job.hadoop_org WHERE event_check IS NULL ORDER BY id LIMIT 1;
update_hadoop_event=UPDATE job.hadoop_event SET event_check = TRUE WHERE event_check IS NULL and file_path = %s

[dir]
hadoop_dir=/hive/job_project/new
```

---
<br>

## â–¶ï¸ ì„œë¹„ìŠ¤ ì‹¤í–‰
```bash
# ì‹œì‘
sudo systemctl start warehouse.service

# ì¤‘ì§€
sudo systemctl stop warehouse.service

# ìƒíƒœ í™•ì¸
sudo systemctl status warehouse.service
```

---
<br>

## ğŸ“œ ë¡œê·¸
- ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜: `$WAREHOUSE_LOG_FILE_YYYYMMDD.log`
- ì˜ˆì‹œ: `/work/job_project/logs/warehouse/warehouse_20260128.log`

---
<br>

## âœ… ì£¼ì˜ ì‚¬í•­
1) Stop íŒŒì¼ (`warehouse.stop`) ìƒì„± ì‹œ ì„œë¹„ìŠ¤ê°€ ì•ˆì „ ì¢…ë£Œë¨
2) **Redis OCR ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šìœ¼ë©´ ëŒ€ê¸° í›„ ì¬ì‹œë„**
3) **HDFS ì—…ë¡œë“œëŠ” Elasticsearch Bulk í¬ë§· ê¸°ì¤€**
4) **gzip NDJSON ê¸°ë°˜ ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ìµœì í™”**
5) **ì²˜ë¦¬ ì™„ë£Œ í›„ ë°˜ë“œì‹œ PostgreSQL ì»¤ë°‹ ìˆ˜í–‰**
---
